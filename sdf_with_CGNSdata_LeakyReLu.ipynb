{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBH+y9aCbQfL+nxk3Jawd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnouarDahdah/SDF_Geometric_Pram/blob/main/sdf_with_CGNSdata_LeakyReLu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnkxEadTKRtB"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchdiffeq import odeint\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import cKDTree\n",
        "import h5py  # Make sure to import h5py to read CGNS files\n",
        "\n",
        "\n",
        "# Step 1: Extract XYZ data from the CGNS file\n",
        "def extract_xyz_data(file_path):\n",
        "    with h5py.File(file_path, 'r') as cgns_file:\n",
        "        # Define the paths to the required data\n",
        "        X = \"/Base/Air Body/GridCoordinates/CoordinateX/ data\"\n",
        "        Y = \"/Base/Air Body/GridCoordinates/CoordinateY/ data\"\n",
        "        Z = \"/Base/Air Body/GridCoordinates/CoordinateZ/ data\"\n",
        "\n",
        "        # Check if paths exist before accessing\n",
        "        if X in cgns_file and Y in cgns_file and Z in cgns_file:\n",
        "            # Extract data from the CGNS file\n",
        "            X = np.array(cgns_file[X])\n",
        "            Y = np.array(cgns_file[Y])\n",
        "            Z = np.array(cgns_file[Z])\n",
        "            return np.vstack((X.flatten(), Y.flatten(), Z.flatten())).T  # Combine into a single array\n",
        "        else:\n",
        "            raise ValueError(\"One or more data paths do not exist in the CGNS file.\")\n",
        "\n",
        "# File path to your CGNS file\n",
        "cgns_file_path = '/content/ID2_Surface.cgns'  # Update with your CGNS file path\n",
        "vertices = extract_xyz_data(cgns_file_path)\n",
        "\n",
        "# Print number of vertices\n",
        "print(f\"Number of vertices: {len(vertices)}\")\n",
        "\n",
        "# Step 2: Create a 3D grid for SDF initialization\n",
        "grid_resolution = 100  # Resolution of the grid\n",
        "x_min, x_max = vertices[:, 0].min() - 1, vertices[:, 0].max() + 1\n",
        "y_min, y_max = vertices[:, 1].min() - 1, vertices[:, 1].max() + 1\n",
        "z_min, z_max = vertices[:, 2].min() - 1, vertices[:, 2].max() + 1\n",
        "\n",
        "# Create a 3D grid of points\n",
        "x = np.linspace(x_min, x_max, grid_resolution)\n",
        "y = np.linspace(y_min, y_max, grid_resolution)\n",
        "z = np.linspace(z_min, z_max, grid_resolution)\n",
        "xx, yy, zz = np.meshgrid(x, y, z)\n",
        "grid_points = np.vstack((xx.ravel(), yy.ravel(), zz.ravel())).T\n",
        "\n",
        "# Step 3: Use KD-Tree for fast nearest neighbor search\n",
        "# Create a KD-Tree for fast nearest neighbor search\n",
        "tree = cKDTree(vertices)\n",
        "\n",
        "# Step 4: Compute the SDF for each grid point\n",
        "sdf_values = tree.query(grid_points)[0]  # Get distances to the nearest surface points\n",
        "sdf_values = torch.tensor(sdf_values, dtype=torch.float32)  # Convert to PyTorch tensor\n",
        "\n",
        "# Step 5: Define the Autoencoder model with more layers and sigmoid activation\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder with 6 layers (including the latent space)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim1),  # First hidden layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),  # Second hidden layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim2, hidden_dim3),  # Third hidden layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim3, hidden_dim4),  # Fourth hidden layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim4, hidden_dim5),  # Fifth hidden layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim5, latent_dim)   # Latent space (sixth layer)\n",
        "        )\n",
        "\n",
        "        # Decoder with 6 layers (mirror image of encoder)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim5),  # First decoder layer (mirror of fifth encoder layer)\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim5, hidden_dim4),  # Second decoder layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim4, hidden_dim3),  # Third decoder layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim3, hidden_dim2),  # Fourth decoder layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim2, hidden_dim1),  # Fifth decoder layer\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim1, input_dim)     # Output layer (same size as input: XYZ + SDF)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_space = self.encoder(x)  # Encode input to latent space\n",
        "        reconstructed = self.decoder(latent_space)  # Decode latent space to reconstruct input\n",
        "        return latent_space, reconstructed\n",
        "\n",
        "# Initialize Autoencoder (input_dim=4 because XYZ + SDF)\n",
        "autoencoder = Autoencoder(input_dim=4, hidden_dim1=128, hidden_dim2=64, hidden_dim3=32, hidden_dim4=16, hidden_dim5=8, latent_dim=8)\n",
        "\n",
        "# Step 6: Define the MLP network for SDF prediction\n",
        "class MLP_SDF_Predictor(nn.Module):\n",
        "    def __init__(self, latent_dim, xyz_dim, hidden_dim, output_dim):\n",
        "        super(MLP_SDF_Predictor, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(latent_dim + xyz_dim, hidden_dim),  # Combine latent space + XYZ\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)  # Predict SDF value\n",
        "        )\n",
        "\n",
        "    def forward(self, latent_space, xyz):\n",
        "        combined_input = torch.cat((latent_space, xyz), dim=1)\n",
        "        return self.network(combined_input)\n",
        "\n",
        "# Initialize MLP (latent_dim=8, xyz_dim=3 for XYZ, hidden_dim=16, output_dim=1 for SDF)\n",
        "mlp_sdf_predictor = MLP_SDF_Predictor(latent_dim=8, xyz_dim=3, hidden_dim=16, output_dim=1)\n",
        "\n",
        "# Step 7: Define the Deformation Field for data enrichment\n",
        "class DeformationField(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(DeformationField, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim)  # Output same dimension as input\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Initialize the deformation field\n",
        "deformation_field = DeformationField(input_dim=3, hidden_dim=64)\n",
        "\n",
        "# Step 8: Define the ODE function for the Neural ODE\n",
        "class ODEFunc(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(ODEFunc, self).__init__()\n",
        "        self.linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, t, h):\n",
        "        return self.linear(h)\n",
        "\n",
        "# Initialize the ODE function\n",
        "ode_func = ODEFunc(hidden_dim=16)\n",
        "\n",
        "# Step 9: Neural ODE solver\n",
        "def neural_ode(h0, t):\n",
        "    return odeint(ode_func, h0, t)\n",
        "\n",
        "# Step 10: Set up the loss function and optimizer\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(list(autoencoder.parameters()) +\n",
        "                             list(mlp_sdf_predictor.parameters()) +\n",
        "                             list(deformation_field.parameters()) +\n",
        "                             list(ode_func.parameters()), lr=0.0005)\n",
        "\n",
        "# Number of training epochs and batch size\n",
        "epochs = 36000\n",
        "t = torch.linspace(0, 1, 50)\n",
        "batch_size = 1024\n",
        "\n",
        "# For plotting loss\n",
        "loss_history = []\n",
        "\n",
        "# Step 11: Training loop\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Randomly sample a subset of grid points for training\n",
        "    indices = torch.randperm(grid_points.shape[0])[:batch_size]\n",
        "    sampled_points = grid_points[indices]\n",
        "\n",
        "    # Convert sampled_points to a PyTorch tensor\n",
        "    sampled_points_tensor = torch.tensor(sampled_points, dtype=torch.float32)\n",
        "    sampled_sdf_values = sdf_values[indices]\n",
        "\n",
        "    # Concatenate XYZ + SDF as input to the autoencoder\n",
        "    autoencoder_input = torch.cat((sampled_points_tensor, sampled_sdf_values.unsqueeze(1)), dim=1)\n",
        "\n",
        "    # Pass through the autoencoder\n",
        "    latent_space, reconstructed_input = autoencoder(autoencoder_input)\n",
        "\n",
        "    # Extract XYZ data from the input for SDF prediction\n",
        "    xyz_data = sampled_points_tensor  # Already a tensor now\n",
        "\n",
        "    # Predict SDF using the MLP from latent space + XYZ data\n",
        "    predicted_sdf = mlp_sdf_predictor(latent_space, xyz_data)\n",
        "\n",
        "    # Reshape predicted_sdf to match the target size\n",
        "    predicted_sdf = predicted_sdf.squeeze()  # Remove the extra dimension\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_fn(predicted_sdf, sampled_sdf_values) + loss_fn(reconstructed_input, autoencoder_input)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Record loss for visualization\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Step 12: Plotting the loss history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_history)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss/scratch/adahdah/siemens/Design_1')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ]
}