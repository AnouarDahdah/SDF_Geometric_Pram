import torch
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import plotly.graph_objects as go
import numpy as np
from scipy.spatial import cKDTree

# Function to generate points on a sphere
def generate_sphere(radius=1, center=np.array([0, 0, 0]), num_points=1000):
    phi = np.random.uniform(0, np.pi, num_points)
    theta = np.random.uniform(0, 2 * np.pi, num_points)
    x = center[0] + radius * np.sin(phi) * np.cos(theta)
    y = center[1] + radius * np.sin(phi) * np.sin(theta)
    z = center[2] + radius * np.cos(phi)
    return np.column_stack((x, y, z))

# Function to create SDF data given sphere parameters
def sdf(grid_res=20):
    grid_min, grid_max = -3, 3
    train_num_points = 1000
    
    x = torch.linspace(grid_min, grid_max, grid_res)
    y = torch.linspace(grid_min, grid_max, grid_res)
    z = torch.linspace(grid_min, grid_max, grid_res)
    xx, yy, zz = torch.meshgrid(x, y, z)
    grid_points = torch.stack([xx.ravel(), yy.ravel(), zz.ravel()], dim=1)

    # Randomly define the sphere's parameters (center and radius)
    center = np.random.uniform(grid_min + 1, grid_max - 1, 3)
    max_radius = np.min([np.abs(center - grid_min), np.abs(center - grid_max)])
    radius = np.random.uniform(0.5, max_radius)
    
    # Generate SDF for grid points
    vertices = generate_sphere(radius, center, train_num_points)
    vertices_tensor = torch.tensor(vertices, dtype=torch.float32)
    tree = cKDTree(vertices_tensor.cpu().numpy())
    sdf_values, _ = tree.query(grid_points.cpu().numpy())
    sdf_values = torch.tensor(sdf_values, dtype=torch.float32)
    
    # Normalize SDF values
    sdf_values = (sdf_values - sdf_values.mean()) / sdf_values.std()
    
    # Sphere parameters as tensor
    params = torch.tensor([*center, radius], dtype=torch.float32)
    
    return sdf_values, grid_points, params

# Function to generate test SDF from specific parameters
def generate_sdf_from_params(center, radius, grid_res=20):
    grid_min, grid_max = -3, 3
    x = torch.linspace(grid_min, grid_max, grid_res)
    y = torch.linspace(grid_min, grid_max, grid_res)
    z = torch.linspace(grid_min, grid_max, grid_res)
    xx, yy, zz = torch.meshgrid(x, y, z)
    grid_points = torch.stack([xx.ravel(), yy.ravel(), zz.ravel()], dim=1)
    
    # Generate sphere points for the given parameters
    train_num_points = 1000
    vertices = generate_sphere(radius, np.array(center), train_num_points)
    vertices_tensor = torch.tensor(vertices, dtype=torch.float32)
    
    # Compute SDF
    tree = cKDTree(vertices_tensor.cpu().numpy())
    sdf_values, _ = tree.query(grid_points.cpu().numpy())
    sdf_values = torch.tensor(sdf_values, dtype=torch.float32)
    
    # Normalize SDF values
    sdf_values = (sdf_values - sdf_values.mean()) / sdf_values.std()
    
    return sdf_values, grid_points

# Generate training data
def generate_training_data(n_training=1000, grid_res=20):
    data_raw = []
    parameters_raw = []
    input_dim = grid_res ** 3

    for _ in range(n_training):
        sdf_values, _, params = sdf(grid_res)
        data_raw.append(sdf_values)
        parameters_raw.append(params)

    return DataLoader(list(zip(data_raw, parameters_raw)), batch_size=10), input_dim

# Define the Autoencoder architecture
class Autoencoder(nn.Module):
    def __init__(self, input_dim):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 4)  # Latent space dimension of 4
        )
        self.decoder = nn.Sequential(
            nn.Linear(4, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, input_dim)
        )

    def forward(self, x):
        latent_space = self.encoder(x)
        reconstructed = self.decoder(latent_space)
        return latent_space, reconstructed

# Define the MLP to map parameters to latent space
class ParamToLatentMLP(nn.Module):
    def __init__(self, param_dim=4, latent_dim=4):
        super(ParamToLatentMLP, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(param_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, latent_dim)
        )

    def forward(self, params):
        return self.network(params)

# Function to test parameters
def test_parameters(autoencoder, param_mlp, center, radius, grid_res=20):
    # Generate test parameters tensor
    test_params = torch.tensor([*center, radius], dtype=torch.float32)
    
    # Generate ground truth SDF for these parameters
    sdf_test, grid_test = generate_sdf_from_params(center, radius, grid_res)
    
    # Get predicted SDF through our pipeline
    with torch.no_grad():
        # Map parameters to latent space
        predicted_latent = param_mlp(test_params.unsqueeze(0))
        
        # Decode latent space to get SDF
        _, predicted_sdf = autoencoder(sdf_test.unsqueeze(0))
        predicted_sdf = predicted_sdf.squeeze()
        
        # Visualize both ground truth and predicted SDF
        fig = go.Figure()
        
        # Ground truth isosurface
        fig.add_trace(go.Isosurface(
            x=grid_test[:, 0].cpu().numpy(),
            y=grid_test[:, 1].cpu().numpy(),
            z=grid_test[:, 2].cpu().numpy(),
            value=sdf_test.cpu().numpy(),
            isomin=-0.1,
            isomax=0.1,
            surface_count=3,
            colorscale='Viridis',
            opacity=0.5,
            caps=dict(x_show=False, y_show=False, z_show=False),
            name='Ground Truth'
        ))
        
        # Predicted isosurface
        fig.add_trace(go.Isosurface(
            x=grid_test[:, 0].cpu().numpy(),
            y=grid_test[:, 1].cpu().numpy(),
            z=grid_test[:, 2].cpu().numpy(),
            value=predicted_sdf.cpu().numpy(),
            isomin=-0.1,
            isomax=0.1,
            surface_count=3,
            colorscale='Plasma',
            opacity=0.5,
            caps=dict(x_show=False, y_show=False, z_show=False),
            name='Predicted'
        ))
        
        fig.update_layout(
            title=f'SDF Comparison for Sphere (Center: {center}, Radius: {radius})',
            scene=dict(aspectmode='data')
        )
        
        fig.show()
        
        # Calculate and return error metrics
        mse = nn.MSELoss()(predicted_sdf, sdf_test)
        return mse.item()

def main():
    # Set parameters
    grid_res = 20
    n_training = 1000
    epochs = 100
    plot_interval = 10
    
    # Generate training data
    training_data, input_dim = generate_training_data(n_training, grid_res)
    
    # Initialize models
    autoencoder = Autoencoder(input_dim)
    param_mlp = ParamToLatentMLP(param_dim=4, latent_dim=4)
    
    # Initialize optimizers
    ae_optimizer = optim.Adam(autoencoder.parameters(), lr=0.0005)
    mlp_optimizer = optim.Adam(param_mlp.parameters(), lr=0.0005)
    
    # Loss functions
    loss_fn_reconstruction = nn.MSELoss()
    loss_fn_latent = nn.MSELoss()
    
    # Generate test case for visualization during training
    sdf_test, grid_test, params_test = sdf(grid_res)
    
    # Training loop
    for epoch in range(epochs):
        for data, parameters in training_data:
            # Autoencoder forward pass
            latent_space, reconstructed = autoencoder(data)
            
            # MLP forward pass
            predicted_latent = param_mlp(parameters)
            
            # Compute losses
            loss_reconstruction = loss_fn_reconstruction(reconstructed, data)
            loss_latent = loss_fn_latent(predicted_latent, latent_space.detach())
            
            total_loss = loss_reconstruction + loss_latent
            
            # Backpropagation
            ae_optimizer.zero_grad()
            mlp_optimizer.zero_grad()
            total_loss.backward()
            ae_optimizer.step()
            mlp_optimizer.step()
        
        if epoch % plot_interval == 0 or epoch == epochs - 1:
            print(f'Epoch {epoch}, Total Loss: {total_loss.item():.6f}, '
                  f'Recon Loss: {loss_reconstruction.item():.6f}, '
                  f'Latent Loss: {loss_latent.item():.6f}')
            
            # Visualize training progress
            with torch.no_grad():
                latent_space_grid, rec = autoencoder(sdf_test)
                fig = go.Figure(data=[go.Isosurface(
                    x=grid_test[:, 0].cpu().numpy(),
                    y=grid_test[:, 1].cpu().numpy(),
                    z=grid_test[:, 2].cpu().numpy(),
                    value=rec.cpu().numpy(),
                    isomin=-0.1,
                    isomax=0.1,
                    surface_count=3,
                    colorscale='Viridis',
                    caps=dict(x_show=False, y_show=False, z_show=False)
                )])
                
                fig.update_layout(
                    title=f'Training Progress: SDF Isosurface at Epoch {epoch}',
                    scene=dict(aspectmode='data')
                )
                
                fig.show()
    
    print("Training completed!")
    
    # Test different parameter combinations
    test_cases = [
        ([0.5, 0.0, 0.0], 1.0),  # Offset in x
        ([0.0, 0.0, 0.0], 1.5),  # Centered, larger
        ([0.5, 0.5, 0.5], 0.8),  # Offset in all directions, smaller
    ]
    
    for center, radius in test_cases:
        mse = test_parameters(autoencoder, param_mlp, center, radius)
        print(f"Test MSE for center={center}, radius={radius}: {mse:.6f}")

if __name__ == "__main__":
    main()
