{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqpB1CauyDtx5vHEdZ+1sK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnouarDahdah/SDF_Geometric_Pram/blob/main/sdf-%3EAE-%3Esdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTGblGq8Gk_x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# Step 1: Load the CSV file for the training dataset\n",
        "csv_filename = '/content/datasurfaceSurface20.csv'\n",
        "data = pd.read_csv(csv_filename, header=None, low_memory=False)\n",
        "\n",
        "# Convert the data to numeric and drop NaNs\n",
        "data = data.apply(pd.to_numeric, errors='coerce').dropna()\n",
        "vertices = torch.tensor(data.values, dtype=torch.float32)  # Convert to PyTorch tensor\n",
        "\n",
        "# Step 2: Create a 3D grid for SDF initialization\n",
        "grid_resolution = 50\n",
        "x_min, x_max = vertices[:, 0].min() - 1, vertices[:, 0].max() + 1\n",
        "y_min, y_max = vertices[:, 1].min() - 1, vertices[:, 1].max() + 1\n",
        "z_min, z_max = vertices[:, 2].min() - 1, vertices[:, 2].max() + 1\n",
        "\n",
        "x = torch.linspace(x_min, x_max, grid_resolution)\n",
        "y = torch.linspace(y_min, y_max, grid_resolution)\n",
        "z = torch.linspace(z_min, z_max, grid_resolution)\n",
        "xx, yy, zz = torch.meshgrid(x, y, z)\n",
        "grid_points = torch.stack([xx.ravel(), yy.ravel(), zz.ravel()], dim=1).to(vertices.device)\n",
        "\n",
        "# Step 3: Use KD-Tree to calculate SDF values for grid points\n",
        "tree = cKDTree(vertices.cpu().numpy())\n",
        "sdf_values_grid, _ = tree.query(grid_points.cpu().numpy())\n",
        "sdf_values_grid = torch.tensor(sdf_values_grid, dtype=torch.float32).to(vertices.device)\n",
        "\n",
        "# Step 4: Define the Autoencoder architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(3, 64),  # Input is 3-dimensional (X, Y, Z)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16)  # Latent space is 16-dimensional\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 3)  # Output is 3-dimensional (X, Y, Z)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent_space = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent_space)\n",
        "        return latent_space, reconstructed\n",
        "\n",
        "# Step 5: Define the MLP for SDF prediction\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(17, 64),  # Latent space (16) + SDF value (1) = 17 input features\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)  # Output is 1-dimensional (predicted SDF value)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Step 6: Initialize models and optimizers\n",
        "autoencoder = Autoencoder().to(vertices.device)\n",
        "mlp = MLP().to(vertices.device)\n",
        "\n",
        "ae_optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "mlp_optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
        "\n",
        "loss_fn_reconstruction = nn.MSELoss()\n",
        "loss_fn_sdf = nn.MSELoss()\n",
        "\n",
        "# Training settings\n",
        "epochs = 5000\n",
        "batch_size = 1024\n",
        "loss_history = []\n",
        "\n",
        "# Step 7: Training loop\n",
        "for epoch in range(epochs):\n",
        "    indices = torch.randperm(grid_points.shape[0])[:batch_size]\n",
        "    batch_points = grid_points[indices]\n",
        "    batch_sdf = sdf_values_grid[indices]\n",
        "\n",
        "    # Autoencoder forward pass\n",
        "    latent_space, reconstructed = autoencoder(batch_points)\n",
        "\n",
        "    # Prepare input for MLP (latent space + batch_sdf)\n",
        "    mlp_input = torch.cat((latent_space, batch_sdf.unsqueeze(1)), dim=1)\n",
        "\n",
        "    # Predict SDF with MLP\n",
        "    predicted_sdf = mlp(mlp_input).squeeze()\n",
        "\n",
        "    # Loss computation\n",
        "    loss_reconstruction = loss_fn_reconstruction(reconstructed, batch_points)\n",
        "    loss_sdf = loss_fn_sdf(predicted_sdf, batch_sdf)\n",
        "    total_loss = loss_reconstruction + loss_sdf\n",
        "\n",
        "    # Backpropagation\n",
        "    ae_optimizer.zero_grad()\n",
        "    mlp_optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    ae_optimizer.step()\n",
        "    mlp_optimizer.step()\n",
        "\n",
        "    loss_history.append(total_loss.item())\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss.item()}')\n",
        "\n",
        "# Step 9: Load unseen data and test the model\n",
        "unseen_csv = '/content/datasurfaceSurface15.csv'\n",
        "unseen_data = pd.read_csv(unseen_csv, header=None, low_memory=False)\n",
        "unseen_data = unseen_data.apply(pd.to_numeric, errors='coerce').dropna()\n",
        "unseen_grid_points = torch.tensor(unseen_data.values, dtype=torch.float32).to(vertices.device)\n",
        "\n",
        "# Use KD-Tree for SDF values on unseen grid points\n",
        "unseen_tree = cKDTree(unseen_grid_points.cpu().numpy())\n",
        "unseen_sdf_values, _ = unseen_tree.query(unseen_grid_points.cpu().numpy())\n",
        "unseen_sdf_values = torch.tensor(unseen_sdf_values, dtype=torch.float32).to(vertices.device)\n",
        "\n",
        "# Autoencoder forward pass for unseen data\n",
        "latent_space_unseen, _ = autoencoder(unseen_grid_points)\n",
        "\n",
        "# Prepare input for MLP (latent space + unseen SDF)\n",
        "mlp_input_unseen = torch.cat((latent_space_unseen, unseen_sdf_values.unsqueeze(1)), dim=1)\n",
        "\n",
        "# Predict SDF for unseen data\n",
        "predicted_sdf_unseen = mlp(mlp_input_unseen).squeeze().detach().cpu().numpy()\n",
        "\n",
        "# Step 10: Save the predicted SDF values to a CSV file\n",
        "predicted_sdf_df = pd.DataFrame({\n",
        "    'X': unseen_grid_points[:, 0].cpu().numpy(),\n",
        "    'Y': unseen_grid_points[:, 1].cpu().numpy(),\n",
        "    'Z': unseen_grid_points[:, 2].cpu().numpy(),\n",
        "    'Predicted_SDF': predicted_sdf_unseen\n",
        "})\n",
        "\n",
        "predicted_sdf_df.to_csv('predicted_sdf_unseen.csv', index=False)\n",
        "print(\"Predicted SDF values have been saved to 'predicted_sdf_unseen.csv'\")\n",
        "\n",
        "# Optional: Save the model state\n",
        "torch.save(autoencoder.state_dict(), 'autoencoder.pth')\n",
        "torch.save(mlp.state_dict(), 'mlp.pth')\n",
        "print(\"Models have been saved as 'autoencoder.pth' and 'mlp.pth'\")\n"
      ]
    }
  ]
}